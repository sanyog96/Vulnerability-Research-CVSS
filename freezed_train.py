import os
import pandas as pd
import numpy as np
import torch
import torch.nn as nn
import torchvision
from transformers import BertTokenizer, BertModel
from transformers import DistilBertTokenizer, DistilBertModel
from torch.utils.data import DataLoader, TensorDataset
from transformers import AdamW
from torch.optim import AdamW
from tqdm import tqdm
from sklearn.preprocessing import LabelEncoder
from sklearn.model_selection import train_test_split
from sklearn.metrics import f1_score, balanced_accuracy_score
import torch.nn.functional as F
import argparse
from transformers import (
    TokenClassificationPipeline,
    AutoModelForTokenClassification,
    AutoTokenizer,
)
from transformers.pipelines import AggregationStrategy
import spacy
import nltk
from nltk.stem import WordNetLemmatizer
nltk.download('wordnet')

# filename = "v3_attack_complexity"
# Check if GPU is available
# print(torch.cuda.is_available())
# print(device)

device = torch.device("cuda:0" if torch.cuda.is_available() else "cpu")

nlp = spacy.load('en_core_web_trf', disable=['parser', 'ner'])
wordnet_lemmatizer = WordNetLemmatizer()

class KeyphraseExtractionPipeline(TokenClassificationPipeline):
    def __init__(self, model, *args, **kwargs):
        super().__init__(
            model=AutoModelForTokenClassification.from_pretrained(model),
            tokenizer=AutoTokenizer.from_pretrained(model),
            device=device,
            *args,
            **kwargs
        )

    def postprocess(self, all_outputs):
        results = super().postprocess(
            all_outputs=all_outputs,
            aggregation_strategy=AggregationStrategy.SIMPLE,
        )
        return np.unique([result.get("word").strip() for result in results])

model_name = "ml6team/keyphrase-extraction-kbir-kpcrowd"
extractor = KeyphraseExtractionPipeline(model=model_name)

def readFile(filename, tokenizer):
    pathtocsv = 'Dataset/raw/' + filename + '.csv'
    # xl = pd.ExcelFile(pathtocsv)
    # res = len(xl.sheet_names)
    # print(res)
    # exit()
    df = pd.read_csv(pathtocsv, sep="\Ä€")

    # df['label_id'].replace('An exploited vulnerability can only affect resources managed by the same security authority. In this case, the vulnerable component and the impacted component are either the same, or both are managed by the same security authority.', 1.0, inplace=True)
    # df['label_id'].replace('An exploited vulnerability can affect resources beyond the security scope managed by the security authority of the vulnerable component. In this case, the vulnerable component and the impacted component are different and managed by different security authorities.', 2.0, inplace=True)
    # df['label_id'].replace('1', 1.0, inplace=True)
    # df['label_id'].replace('2', 2.0, inplace=True)
    # print(set(list(df['label_id'])))
    df.dropna(subset=['description', 'label_id'], inplace=True)
    print(len(df))
    # exit()
    # df['label_id'].replace('Specialized access conditions or extenuating circumstances do not exist. An attacker can expect repeatable success when attacking the vulnerable component.', '1', inplace=True)
    # df['label_id'].replace(1.0, '1', inplace=True)
    # df['label_id'].replace(2.0, '2', inplace=True)
    # df['label_id'].replace(2.0, '2', inplace=True)
    # df['label_id'].fillna('1', inplace=True)
    labels = df['label_id']

    num_labels_des = len(df['label_id'].unique())
    text_description = list(df['description'].astype(str))
    descriptions = []
    for text in text_description:
        # print(text)
        text = text.replace("\n", " ")
        # spacy lemmatizer
        # text = nlp(text)
        # text = " ".join([token.lemma_ for token in text])
        text = " ".join([wordnet_lemmatizer.lemmatize(word) for word in nltk.word_tokenize(text)])
        # print(text)
        keyphrases = extractor(text)
        keyphrases = keyphrases
        descriptions.append("; ".join(keyphrases))
    # print(df['description'].count_nan())
    #initializing label encoder
    encoder = LabelEncoder()
    enc_labels = encoder.fit_transform(labels)

    inputs = tokenizer(descriptions, padding=True, truncation=True, return_tensors="pt")
    
    input_ids_train, input_ids_test, labels_train, labels_test = train_test_split(inputs['input_ids'], enc_labels, test_size=0.2, random_state=42)
    input_ids_train, input_ids_valid, labels_train, labels_valid = train_test_split(input_ids_train, labels_train, test_size=0.1, random_state=42)
    
    train_dataset = TensorDataset(input_ids_train, torch.tensor(labels_train))
    train_loader = DataLoader(train_dataset, batch_size=512, shuffle=True)
    valid_dataset = TensorDataset(input_ids_valid, torch.tensor(labels_valid))
    valid_loader = DataLoader(valid_dataset, batch_size=64, shuffle=True)
    test_dataset = TensorDataset(input_ids_test, torch.tensor(labels_test))
    test_loader = DataLoader(test_dataset, batch_size=64, shuffle=False)
    return train_loader, valid_loader, test_loader, num_labels_des

# Load pre-trained BERT model and tokenizer

# Define MLP on top of BERT encoder
class MLP(nn.Module):
    def __init__(self, input_size, hidden_size, num_classes):
        super(MLP, self).__init__()
        self.fc1 = nn.Linear(input_size, hidden_size)
        self.relu1 = nn.ReLU()
        self.fc2 = nn.Linear(hidden_size, hidden_size)
        self.relu2 = nn.ReLU()
        self.fc3 = nn.Linear(hidden_size, num_classes)
    
    def forward(self, x):
        out = self.fc1(x)
        out = self.relu1(out)
        out = self.fc2(out)
        out = self.relu2(out)
        out = self.fc3(out)
        return out

class FocalLossBCE(torch.nn.Module):
    def __init__(
            self,
            alpha: float = 0.25,
            gamma: float = 2,
            reduction: str = "mean",
            bce_weight: float = 1.0,
            focal_weight: float = 1.0,
            num_labels_des: int = 2,
    ):
        super().__init__()
        self.alpha = alpha
        self.gamma = gamma
        self.reduction = reduction
        self.bce = torch.nn.CrossEntropyLoss(reduction=reduction)
        self.bce_weight = bce_weight
        self.focal_weight = focal_weight
        self.num_labels_des = num_labels_des

    def forward(self, logits, targets):
        focall_loss = torchvision.ops.focal_loss.sigmoid_focal_loss(
            inputs=logits,
            targets=F.one_hot(targets, num_classes=self.num_labels_des).float(),
            alpha=self.alpha,
            gamma=self.gamma,
            reduction=self.reduction,
        )
        bce_loss = self.bce(logits, targets)
        return self.bce_weight * bce_loss + self.focal_weight * focall_loss

input_size = 768  # BERT hidden size
hidden_size = 256

def evaluate(bert_model, mlp_model, criterion, num_labels_des, loader, foldername, filename, mode="validate"):
    total_correct = 0
    total_samples = 0
    all_predicted = []
    all_labels = []
    total_loss = 0
    if(mode == 'test'):
        mlp_model = MLP(input_size, hidden_size, num_labels_des).to(device)
        mlp_model.load_state_dict(torch.load('checkpoints/' + foldername + '/distillbert_mlp_model_' + filename + '_best.pth'))
    mlp_model.eval()
    with torch.no_grad():
        for batch in loader:
            input_ids, labels = batch[0].to(device), batch[1].to(device)
            bert_output = bert_model(input_ids)[0][:, 0, :]  # Using [CLS] token representation for classification
            outputs = mlp_model(bert_output)
            _, predicted = torch.max(outputs, 1)
            # print(predicted.shape)
            # print(labels.shape)
            # print(labels.detach().cpu().tolist())
            # print(list(labels.cpu()))
            loss = criterion(outputs, labels)
            total_samples += labels.size(0)
            total_correct += (predicted == labels).sum().item()
            all_predicted.append(predicted.detach().cpu().tolist())
            all_labels.append(labels.detach().cpu().tolist())
            total_loss += loss.item()
    accuracy = total_correct / total_samples
    valid_loss = total_loss / len(loader)
    all_predicted = all_predicted[0]
    all_labels = all_labels[0]
    f1_score_micro = f1_score(np.array(all_predicted), np.array(all_labels), average='micro')
    f1_score_macro = f1_score(np.array(all_predicted), np.array(all_labels), average='macro')
    # print(all_labels[0])
    # print(all_predicted[0])
    balanced_score = balanced_accuracy_score(all_labels, all_predicted)
    print("Accuracy on {} set: {}".format(mode, accuracy))
    print("F1 score (micro for imbalanced dataset) : {}".format(f1_score_micro))
    print("F1 score (macro for imbalanced dataset) : {}".format(f1_score_macro))
    print("Balanced Accuracy score : {}".format(balanced_score))
    score = tuple([accuracy, f1_score_micro, f1_score_macro, balanced_score])
    if mode == "test":
        with open("results.txt", "a") as f1:
            f1.write(filename + "|" + mode + "|" + str(accuracy) + "|" + str(f1_score_micro) + "|" + str(f1_score_macro) + "|" + str(balanced_score) + "|" + str(foldername) + "\n")
    return valid_loss, score

def train(bert_model, mlp_model, criterion, optimizer, train_loader, valid_loader, epochs, foldername, filename, num_labels_des):
    trainloss = []
    valid_loss_array = []
    old_validation_loss = float('inf')
    old_valid_balanced_score = float('-inf')
    for epoch in range(epochs):
        mlp_model.train()
        total_loss = 0
        with tqdm(train_loader, desc=f"Epoch {epoch+1}") as progress_bar:
            for batch in progress_bar:
                input_ids, labels = batch[0].to(device), batch[1].to(device)
                with torch.no_grad():
                    bert_output = bert_model(input_ids)[0][:, 0, :]  # Using [CLS] token representation for classification
                optimizer.zero_grad()
                outputs = mlp_model(bert_output)
                loss = criterion(outputs, labels)
                loss.backward()
                optimizer.step()
                total_loss += loss.item()
                progress_bar.set_postfix({'loss': total_loss / len(train_loader)})
        trainloss.append(total_loss / len(train_loader))
        curr_validation_loss, curr_valid_score = evaluate(bert_model, mlp_model, criterion, num_labels_des, valid_loader, foldername, filename, "validate")
        valid_loss_array.append(curr_validation_loss)
        if(curr_validation_loss < old_validation_loss):
            old_validation_loss = curr_validation_loss
            torch.save(mlp_model.state_dict(), 'checkpoints/' + foldername + '/distillbert_mlp_model_' + filename + '_best.pth')
        # if(curr_valid_score[-1] > old_valid_balanced_score):
        #     old_valid_balanced_score = curr_valid_score[-1]
        #     torch.save(mlp_model.state_dict(), 'checkpoints/lemmatized_keyphrase_freezed/distillbert_mlp_model_' + filename + '_best.pth')
    if 'losses/' + foldername + '/train_loss_' + filename + '.npy':
        existing_train_loss = np.load("losses/" + foldername + "/train_loss_" + filename + ".npy")
        trainloss = np.append(existing_train_loss, np.array(trainloss))
    if 'losses/' + foldername + '/valid_loss_' + filename + '.npy':
        existing_valid_loss = np.load("losses/" + foldername + "/valid_loss_" + filename + ".npy")
        valid_loss_array = np.append(existing_valid_loss, np.array(valid_loss_array))
    np.save('losses/' + foldername + '/train_loss_' + filename + '.npy', np.array(trainloss), allow_pickle=True)
    np.save('losses/' + foldername + '/valid_loss_' + filename + '.npy', np.array(valid_loss_array), allow_pickle=True)
    torch.save(mlp_model.state_dict(), 'checkpoints/' + foldername + '/distillbert_mlp_model_' + filename + '_last.pth')

def main(args):
    # tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')
    # bert_model = BertModel.from_pretrained('bert-base-uncased').to(device)
    tokenizer = DistilBertTokenizer.from_pretrained('distilbert-base-uncased')
    bert_model = DistilBertModel.from_pretrained("distilbert-base-uncased").to(device)
    # Freeze BERT parameters
    if args.freezed:
        for param in bert_model.parameters():
            param.requires_grad = False
    
    print("loading data..")
    train_loader, valid_loader, test_loader, num_labels_des = readFile(args.filename, tokenizer)
    print("loaded data...")
    mlp_model = MLP(input_size, hidden_size, num_labels_des).to(device)
    if os.path.exists('checkpoints/' + args.foldername + '/distillbert_mlp_model_' + args.filename + '_best.pth'):
        mlp_model.load_state_dict(torch.load('checkpoints/' + args.foldername + '/distillbert_mlp_model_' + args.filename + '_best.pth'))
    # criterion = nn.CrossEntropyLoss()
    criterion = FocalLossBCE(num_labels_des=num_labels_des)

    optimizer = torch.optim.Adam(mlp_model.parameters(), lr=0.001)
    # optimizer = AdamW(mlp_model.parameters(), lr=0.0001, weight_decay=1e-6)
    if not args.test:
        print("training started.....")
        train(bert_model, mlp_model, criterion, optimizer, train_loader, valid_loader, args.epochs, args.foldername, args.filename, num_labels_des)
    print("testing started......")
    test_loss, test_score = evaluate(bert_model, mlp_model, criterion, num_labels_des, test_loader, args.foldername, args.filename, "test")

def cli_main():
    parser = argparse.ArgumentParser(description="freezed training part with DistillBERT")
    parser.add_argument("-f", "--filename", type=str, dest="filename", required=True, help="datafilename in Dataset folder")
    parser.add_argument("-e", "--epochs", type=int, dest="epochs", required=True, help="epochs to train the model")
    parser.add_argument("-d", "--foldername", type=str, dest="foldername", required=True, help="foldername to store the checkpoint and loss file")
    parser.add_argument('--freezed', action='store_true', help='if set, the encoder model will be tuned')
    parser.add_argument('--test', action='store_true', help='apply only on test dataset')
    # parser.add_argument('--lemmatize', action='store_true', help='lemmatization to be applied on description part of dataset')
    args = parser.parse_args()
    main(args)

if __name__ == '__main__':
    cli_main()
